<h1>Glosario de Términos de IA y LLMs</h1>

Preparar una presentación donde hablen sobre cada uno de los siguientes puntos, el objetivo es ser breves pero claros. 

# Angel, Federico y Jesús

## Arquitecturas y Modelos
- Transformers y Attention (explicar brevemente)
- MoE (Mixture of Experts)
- Decoder-only vs Encoder-Decoder
- Autoregressive Models
- Foundation Models
- Parameters
- Tokenization

## Herramientas
- Hugging Face
- LangChain
- Ollama

# Eddel y Gerardo

## Generación de Texto
- Temperature
- Top-k Sampling
- Top-p Sampling

## Técnicas Avanzadas
- RAG
- Agents
- Multimodality

# Sebastian y Feliciano

## Evaluación
- Hallucinations (presenten ejemplos propios y encontrados)
- Benchmarks: concepto y ejemplos (MMLU, HumanEval, GLUE)
- Ranking actual de modelos en cada uno de los 3 benchmarks anteriores
- Perplexity ¿cómo se definen? ¿para qué tipo de tareas se usan?
- BLEU/ROUGE Score. ¿cómo se definen? ¿para qué tipo de tareas se usan?


# Luis Fernando y Manuel

## Entrenamiento y Ajuste
- Alignment
- Pre-training vs Fine-tuning: Qué es cada uno y diferencias
- RLHF
- PEFT

## Principales modelos: Llama, GPT/o1, Claude, Mistral, DeepSeek, Qwen, Kimi, GLM, Gemini
- Compañías desarrolladoras
- Origen geográfico y año de lanzamiento
- Tipo de licencia
- Versiones y accesos: para cada modelo, identificar producto comercial vs. modelo base vs. implementación open-source (este último punto busquen si hay alguna versión del modelo en HuggingFace)

# Jennifer y Kevin

## Optimización
- Quantization
- Knowledge Distillation

## Seguridad y Ética
- Censura
- Jailbreaking
- Prompt Injection
- Sesgos


# Arian y Catherine

## Prompting: En cada uno dar ejemplos, definición y utilidad
- Prompt Engineering
- Context Size
- Role Prompting
- Zero-shot, One-shot, Few-shot
- Chain-of-Thought (CoT)
- Instruction Prompting
- Tree of Thoughts
- ReAct
