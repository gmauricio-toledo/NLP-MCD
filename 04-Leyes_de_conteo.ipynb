{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNHBZwEfNOzCnerwiQzLFMw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmauricio-toledo/NLP-MCD/blob/main/04-Leyes_de_conteo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Leyes de frecuencia</h1>\n",
        "\n",
        "Las leyes de frecuencias son principios matemáticos y estadísticos que describen patrones predecibles en la distribución de frecuencias de elementos dentro de un conjunto de datos aparentemente caótico. Dos de las más representativas son la **Ley de Benford** y la **Ley de Zipf**.\n",
        "\n",
        "Ambas revelan un orden subyacente en sistemas naturales y sociales, y se han convertido en herramientas poderosas para detectar anomalías. La Ley de Benford se utiliza principalmente para identificar posibles fraudes en datos financieros, electorales o científicos, mientras que la Ley de Zipf es fundamental en lingüística y ciencias de la información."
      ],
      "metadata": {
        "id": "LVIF7IqqU3Yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ley de Zipf\n",
        "\n",
        "Esta ley postula que en muchos rankings naturales (como la frecuencia de palabras en un idioma, el tamaño de las ciudades o el tráfico de sitios web), la frecuencia de un elemento es inversamente proporcional a su rango en la lista. Es decir, el elemento más frecuente (rango 1) aparecerá aproximadamente el doble de veces que el del rango 2, el triple que el del rango 3, y así sucesivamente. Se usa para entender fenómenos de popularidad y escalabilidad, siendo crucial en campos como el el análisis de big data y la sociología."
      ],
      "metadata": {
        "id": "j6m_lwamQXqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaQlMq7TJusq"
      },
      "outputs": [],
      "source": [
        "!gdown 18kGdlhOiQNS61wUK7uPbdquKL3XJrgzf\n",
        "!gdown 14nqDnZ3oDXqRtIcrpB6IP1f_NZP_Gb08"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# df = pd.read_csv('IMDB.csv')\n",
        "# df.rename(columns={'review': 'text'}, inplace=True)\n",
        "\n",
        "df = pd.read_csv('YoutubeCommentsDataSet.csv', index_col=0)\n",
        "df.dropna()\n",
        "df.rename(columns={'Comment': 'text'}, inplace=True)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "fWzPxGEVJ-9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a63f331d"
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    if isinstance(text, str):  # Solo procesar si es string\n",
        "        clean = re.compile('<.*?>')\n",
        "        return re.sub(clean, '', text)\n",
        "    else:  # Para NaN, None\n",
        "        return \"\"\n",
        "\n",
        "df['text'] = df['text'].apply(remove_html_tags)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def tokenize(text):\n",
        "    return [t for t in word_tokenize(text.lower()) if t not in punctuation]\n",
        "\n",
        "df['text'] = df['text'].apply(tokenize)\n",
        "df"
      ],
      "metadata": {
        "id": "yVXrBzNOKX1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = []\n",
        "\n",
        "for doc in df['text']:\n",
        "    all_tokens.extend(doc)\n",
        "\n",
        "len(all_tokens)"
      ],
      "metadata": {
        "id": "peDBom1qK4tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Contar frecuencias\n",
        "word_counts = Counter(all_tokens)\n",
        "most_common = word_counts.most_common()\n",
        "\n",
        "# Separar palabras y frecuencias\n",
        "words = [item[0] for item in most_common]\n",
        "frequencies = [item[1] for item in most_common]\n",
        "ranks = range(1, len(frequencies) + 1)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "top_n = 20\n",
        "top_words = words[:top_n]\n",
        "top_freqs = frequencies[:top_n]\n",
        "ax1.bar(range(top_n), top_freqs)\n",
        "ax1.set_title(f'Top {top_n} palabras más frecuentes')\n",
        "ax1.set_xlabel('Palabra')\n",
        "ax1.set_ylabel('Frecuencia')\n",
        "ax1.set_xticks(range(top_n))\n",
        "ax1.set_xticklabels(top_words, rotation=45, ha='right')\n",
        "\n",
        "ax2.loglog(ranks, frequencies, 'b-', linewidth=1)\n",
        "ax2.set_title('Ley de Zipf - Escala logarítmica')\n",
        "ax2.set_xlabel('Rango (log)')\n",
        "ax2.set_ylabel('Frecuencia (log)')\n",
        "ax2.grid(True, which=\"both\", ls=\"-\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2HoGWUyuMjNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ley de Benford\n",
        "\n",
        "También conocida como la \"Ley del Primer Dígito\", establece que en muchos conjuntos de datos numéricos de la vida real (como facturas, precios de acciones, población de ciudades o constantes físicas), el dígito 1 aparece como primer dígito significativo con mucha más frecuencia que el resto (aproximadamente el 30% de las veces), seguido por el 2, y así sucesivamente, hasta el 9, que aparece menos del 5% de las veces. Su utilidad principal radica en la detección de fraudes y anomalías, ya que los datos inventados por humanos suelen distribuir los dígitos de forma más uniforme."
      ],
      "metadata": {
        "id": "nQs9sflxQMjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1RH-yxb-zir8C_8fDltIcztt1Dyo5xZNyfRS2FoE96kc"
      ],
      "metadata": {
        "id": "rKXcc1dONWYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prices_df = pd.read_excel('Actividad precios.xlsx')\n",
        "prices_df"
      ],
      "metadata": {
        "id": "z5BPP06KRCEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "prices = prices_df.iloc[:,1:].values\n",
        "prices.shape"
      ],
      "metadata": {
        "id": "U-cancqyRJNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prices = prices.reshape(-1,)\n",
        "\n",
        "leading_digits = []\n",
        "\n",
        "for x in prices:\n",
        "    number = str(x)\n",
        "    leading_digits.append(int(number[0]))\n",
        "\n",
        "leading_digits = np.array(leading_digits)"
      ],
      "metadata": {
        "id": "xI1qguHURgvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Contar frecuencias\n",
        "digit_counts = Counter(leading_digits)\n",
        "sorted_countings = digit_counts.most_common()\n",
        "\n",
        "# Extraer dígitos y conteos en el orden deseado\n",
        "digits = [d for d, _ in sorted_countings]\n",
        "counts = [count for _, count in sorted_countings]\n",
        "\n",
        "# Crear el gráfico con posiciones numéricas\n",
        "plt.figure(figsize=(10, 5))\n",
        "x_positions = range(len(digits))\n",
        "plt.bar(x_positions, counts)\n",
        "\n",
        "# Etiquetas en el orden correcto\n",
        "plt.xticks(x_positions, digits)\n",
        "plt.xlabel('Dígito')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Distribución del primer dígito (ordenado por frecuencia)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EeCw_y-JRx3q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}